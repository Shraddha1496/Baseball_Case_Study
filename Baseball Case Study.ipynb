{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseball Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "This dataset utilizes data from 2014 Major League Baseball seasons in order to develop an algorithm that predicts the number of wins for a given team in the 2015 season based on several different indicators of success. There are 16 different features that will be used as the inputs to the machine learning and the output will be a value that represents the number of wins. <br>\n",
    "\n",
    "-- Input features: Runs, At Bats, Hits, Doubles, Triples, Homeruns, Walks, Strikeouts, Stolen Bases, Runs Allowed, Earned Runs, Earned Run Average (ERA), Shutouts, Saves, Complete Games and Errors<br>\n",
    "\n",
    "-- Output: Number of predicted wins (W)<br>\n",
    "\n",
    "To understand the columns meaning, follow the link given below to understand the baseball statistics:<br> https://en.wikipedia.org/wiki/Baseball_statistics<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore,boxcox\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import power_transform, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('baseball.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Linear Regression</b> Model needs to be used for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs, At Bats, Hits, Doubles, Triples, Homeruns, Walks, Strikeouts, Stolen Bases, Runs Allowed, Earned Runs, Earned Run Average (ERA), Shutouts, Saves, and Errors <br>\n",
    "\n",
    "   <b>Input features:</b><br>\n",
    "    R  - Runs<br>\n",
    "    AB - At Bats<br>\n",
    "    H  - Hits<br>\n",
    "    2B - Doubles<br>\n",
    "    3B - Triples<br>\n",
    "    HR - Homeruns<br>\n",
    "    BB - Walks<br>\n",
    "    SO - Strikeouts<br>\n",
    "    SB - Stolen Bases<br>\n",
    "    RA - Run Allowed<br>\n",
    "    ER - Earned Runs<br>\n",
    "    ERA - Earned Run Average (ERA)<br>\n",
    "    CG - Complete games ( referred online)<br>\n",
    "    SHO - Shutouts<br>\n",
    "    SV - Saves<br>\n",
    "    E - Errors<br>\n",
    "  ----------------------------------------------------<br>  \n",
    " <b>Output features:</b><br>\n",
    "    W -Number of predicted wins (W)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - There are 30 rows and 17 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - All values are in numeric only so need to use label encoder.\n",
    " - There are 16 integers and 1 float present in dataset.\n",
    " - There are no categorical values in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - No null values in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck null\n",
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Recheck null, showing no null values in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Some of the columns having outliers and skewness, have to observe that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,0:10].plot(kind='box',subplots=True,layout=(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,10:].plot(kind='box',subplots=True,layout=(2,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - R,ERA,SHO,SV have outliers.\n",
    " - Other colums don't have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univarient Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['E'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['R'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking skewness\n",
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - As per standards(<0.5), there are skewness presnt in R,H,CG,SHO,SV,E\n",
    " - We need to handle the skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking distribution plot for more detail\n",
    "\n",
    "for i in df.columns:\n",
    "    plt.figure()\n",
    "    sns.distplot(df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking correlation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - As per the above plot R,H,HR,SO,SHO,CG,E having some skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - RA,ER,ERA are highly -vely correlated with target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bavarient Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.R,df.W)\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Wins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs relation with dataset\n",
    "for i in df.columns:\n",
    "    plt.figure()\n",
    "    sns.barplot(x=df[i],y=df.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Relationship between features and label have been observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing outliers from data\n",
    "z = np.abs(zscore(df))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[(z<3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape of new dataset\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing highly negative correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop(['RA','ER'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop(['ERA',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting X & Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_new.iloc[:,1:-1]\n",
    "y = df_new['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>HR</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>SB</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>724</td>\n",
       "      <td>5575</td>\n",
       "      <td>1497</td>\n",
       "      <td>300</td>\n",
       "      <td>42</td>\n",
       "      <td>139</td>\n",
       "      <td>383</td>\n",
       "      <td>973</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>696</td>\n",
       "      <td>5467</td>\n",
       "      <td>1349</td>\n",
       "      <td>277</td>\n",
       "      <td>44</td>\n",
       "      <td>156</td>\n",
       "      <td>439</td>\n",
       "      <td>1264</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>669</td>\n",
       "      <td>5439</td>\n",
       "      <td>1395</td>\n",
       "      <td>303</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>533</td>\n",
       "      <td>1157</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622</td>\n",
       "      <td>5533</td>\n",
       "      <td>1381</td>\n",
       "      <td>260</td>\n",
       "      <td>27</td>\n",
       "      <td>136</td>\n",
       "      <td>404</td>\n",
       "      <td>1231</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>689</td>\n",
       "      <td>5605</td>\n",
       "      <td>1515</td>\n",
       "      <td>289</td>\n",
       "      <td>49</td>\n",
       "      <td>151</td>\n",
       "      <td>455</td>\n",
       "      <td>1259</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>764</td>\n",
       "      <td>5567</td>\n",
       "      <td>1397</td>\n",
       "      <td>272</td>\n",
       "      <td>19</td>\n",
       "      <td>212</td>\n",
       "      <td>554</td>\n",
       "      <td>1227</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>713</td>\n",
       "      <td>5485</td>\n",
       "      <td>1370</td>\n",
       "      <td>246</td>\n",
       "      <td>20</td>\n",
       "      <td>217</td>\n",
       "      <td>418</td>\n",
       "      <td>1331</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>644</td>\n",
       "      <td>5485</td>\n",
       "      <td>1383</td>\n",
       "      <td>278</td>\n",
       "      <td>32</td>\n",
       "      <td>167</td>\n",
       "      <td>436</td>\n",
       "      <td>1310</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>748</td>\n",
       "      <td>5640</td>\n",
       "      <td>1495</td>\n",
       "      <td>294</td>\n",
       "      <td>33</td>\n",
       "      <td>161</td>\n",
       "      <td>478</td>\n",
       "      <td>1148</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>751</td>\n",
       "      <td>5511</td>\n",
       "      <td>1419</td>\n",
       "      <td>279</td>\n",
       "      <td>32</td>\n",
       "      <td>172</td>\n",
       "      <td>503</td>\n",
       "      <td>1233</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>729</td>\n",
       "      <td>5459</td>\n",
       "      <td>1363</td>\n",
       "      <td>278</td>\n",
       "      <td>26</td>\n",
       "      <td>230</td>\n",
       "      <td>486</td>\n",
       "      <td>1392</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>661</td>\n",
       "      <td>5417</td>\n",
       "      <td>1331</td>\n",
       "      <td>243</td>\n",
       "      <td>21</td>\n",
       "      <td>176</td>\n",
       "      <td>435</td>\n",
       "      <td>1150</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>656</td>\n",
       "      <td>5544</td>\n",
       "      <td>1379</td>\n",
       "      <td>262</td>\n",
       "      <td>22</td>\n",
       "      <td>198</td>\n",
       "      <td>478</td>\n",
       "      <td>1336</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>694</td>\n",
       "      <td>5600</td>\n",
       "      <td>1405</td>\n",
       "      <td>277</td>\n",
       "      <td>46</td>\n",
       "      <td>146</td>\n",
       "      <td>475</td>\n",
       "      <td>1119</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>647</td>\n",
       "      <td>5484</td>\n",
       "      <td>1386</td>\n",
       "      <td>288</td>\n",
       "      <td>39</td>\n",
       "      <td>137</td>\n",
       "      <td>506</td>\n",
       "      <td>1267</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>697</td>\n",
       "      <td>5631</td>\n",
       "      <td>1462</td>\n",
       "      <td>292</td>\n",
       "      <td>27</td>\n",
       "      <td>140</td>\n",
       "      <td>461</td>\n",
       "      <td>1322</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>689</td>\n",
       "      <td>5491</td>\n",
       "      <td>1341</td>\n",
       "      <td>272</td>\n",
       "      <td>30</td>\n",
       "      <td>171</td>\n",
       "      <td>567</td>\n",
       "      <td>1518</td>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>655</td>\n",
       "      <td>5480</td>\n",
       "      <td>1378</td>\n",
       "      <td>274</td>\n",
       "      <td>34</td>\n",
       "      <td>145</td>\n",
       "      <td>412</td>\n",
       "      <td>1299</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>640</td>\n",
       "      <td>5571</td>\n",
       "      <td>1382</td>\n",
       "      <td>257</td>\n",
       "      <td>27</td>\n",
       "      <td>167</td>\n",
       "      <td>496</td>\n",
       "      <td>1255</td>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>683</td>\n",
       "      <td>5527</td>\n",
       "      <td>1351</td>\n",
       "      <td>295</td>\n",
       "      <td>17</td>\n",
       "      <td>177</td>\n",
       "      <td>488</td>\n",
       "      <td>1290</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>703</td>\n",
       "      <td>5428</td>\n",
       "      <td>1363</td>\n",
       "      <td>265</td>\n",
       "      <td>13</td>\n",
       "      <td>177</td>\n",
       "      <td>539</td>\n",
       "      <td>1344</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>613</td>\n",
       "      <td>5463</td>\n",
       "      <td>1420</td>\n",
       "      <td>236</td>\n",
       "      <td>40</td>\n",
       "      <td>120</td>\n",
       "      <td>375</td>\n",
       "      <td>1150</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>573</td>\n",
       "      <td>5420</td>\n",
       "      <td>1361</td>\n",
       "      <td>251</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>471</td>\n",
       "      <td>1107</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>626</td>\n",
       "      <td>5529</td>\n",
       "      <td>1374</td>\n",
       "      <td>272</td>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>387</td>\n",
       "      <td>1274</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>667</td>\n",
       "      <td>5385</td>\n",
       "      <td>1346</td>\n",
       "      <td>263</td>\n",
       "      <td>26</td>\n",
       "      <td>187</td>\n",
       "      <td>563</td>\n",
       "      <td>1258</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>696</td>\n",
       "      <td>5565</td>\n",
       "      <td>1486</td>\n",
       "      <td>288</td>\n",
       "      <td>39</td>\n",
       "      <td>136</td>\n",
       "      <td>457</td>\n",
       "      <td>1159</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>720</td>\n",
       "      <td>5649</td>\n",
       "      <td>1494</td>\n",
       "      <td>289</td>\n",
       "      <td>48</td>\n",
       "      <td>154</td>\n",
       "      <td>490</td>\n",
       "      <td>1312</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>650</td>\n",
       "      <td>5457</td>\n",
       "      <td>1324</td>\n",
       "      <td>260</td>\n",
       "      <td>36</td>\n",
       "      <td>148</td>\n",
       "      <td>426</td>\n",
       "      <td>1327</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>737</td>\n",
       "      <td>5572</td>\n",
       "      <td>1479</td>\n",
       "      <td>274</td>\n",
       "      <td>49</td>\n",
       "      <td>186</td>\n",
       "      <td>388</td>\n",
       "      <td>1283</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      R    AB     H   2B  3B   HR   BB    SO   SB  CG  SHO  SV\n",
       "0   724  5575  1497  300  42  139  383   973  104   2    8  56\n",
       "1   696  5467  1349  277  44  156  439  1264   70   2   12  45\n",
       "2   669  5439  1395  303  29  141  533  1157   86  11   10  38\n",
       "3   622  5533  1381  260  27  136  404  1231   68   7    9  37\n",
       "4   689  5605  1515  289  49  151  455  1259   83   7   12  35\n",
       "6   764  5567  1397  272  19  212  554  1227   63   3    4  48\n",
       "7   713  5485  1370  246  20  217  418  1331   44   0   10  43\n",
       "8   644  5485  1383  278  32  167  436  1310   87   1   12  60\n",
       "9   748  5640  1495  294  33  161  478  1148   71   3   10  40\n",
       "10  751  5511  1419  279  32  172  503  1233  101   5    9  45\n",
       "11  729  5459  1363  278  26  230  486  1392  121   5   13  39\n",
       "12  661  5417  1331  243  21  176  435  1150   52   2   12  46\n",
       "13  656  5544  1379  262  22  198  478  1336   69   6   12  45\n",
       "14  694  5600  1405  277  46  146  475  1119   78   5   15  28\n",
       "15  647  5484  1386  288  39  137  506  1267   69   1   15  62\n",
       "16  697  5631  1462  292  27  140  461  1322   98   0   13  54\n",
       "17  689  5491  1341  272  30  171  567  1518   95   6   21  48\n",
       "18  655  5480  1378  274  34  145  412  1299   84   1    7  40\n",
       "19  640  5571  1382  257  27  167  496  1255  134   2    8  35\n",
       "20  683  5527  1351  295  17  177  488  1290   51   1   14  50\n",
       "21  703  5428  1363  265  13  177  539  1344   57   4   13  41\n",
       "22  613  5463  1420  236  40  120  375  1150  112   0   12  35\n",
       "23  573  5420  1361  251  18  100  471  1107   69   3   10  44\n",
       "24  626  5529  1374  272  37  130  387  1274   88   1    7  35\n",
       "25  667  5385  1346  263  26  187  563  1258   59   6   21  47\n",
       "26  696  5565  1486  288  39  136  457  1159   93   7   18  41\n",
       "27  720  5649  1494  289  48  154  490  1312  132   1   12  44\n",
       "28  650  5457  1324  260  36  148  426  1327   82   1    6  41\n",
       "29  737  5572  1479  274  49  186  388  1283   97   4    4  36"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      95\n",
       "1      83\n",
       "2      81\n",
       "3      76\n",
       "4      74\n",
       "6      87\n",
       "7      81\n",
       "8      80\n",
       "9      78\n",
       "10     88\n",
       "11     86\n",
       "12     85\n",
       "13     76\n",
       "14     68\n",
       "15    100\n",
       "16     98\n",
       "17     97\n",
       "18     68\n",
       "19     64\n",
       "20     90\n",
       "21     83\n",
       "22     71\n",
       "23     67\n",
       "24     63\n",
       "25     92\n",
       "26     84\n",
       "27     79\n",
       "28     74\n",
       "29     68\n",
       "Name: W, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = power_transform(x)\n",
    "df_x = pd.DataFrame(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.685188</td>\n",
       "      <td>1.006150</td>\n",
       "      <td>-0.741927</td>\n",
       "      <td>-1.605198</td>\n",
       "      <td>-2.550612</td>\n",
       "      <td>0.936132</td>\n",
       "      <td>-0.307098</td>\n",
       "      <td>-0.787002</td>\n",
       "      <td>1.532753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138198</td>\n",
       "      <td>1.185227</td>\n",
       "      <td>-0.109958</td>\n",
       "      <td>-0.462096</td>\n",
       "      <td>0.093683</td>\n",
       "      <td>-0.516377</td>\n",
       "      <td>-0.307098</td>\n",
       "      <td>0.236737</td>\n",
       "      <td>0.312020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.907385</td>\n",
       "      <td>-0.228819</td>\n",
       "      <td>-0.664354</td>\n",
       "      <td>1.232098</td>\n",
       "      <td>-0.935611</td>\n",
       "      <td>0.225038</td>\n",
       "      <td>2.011315</td>\n",
       "      <td>-0.252844</td>\n",
       "      <td>-0.664137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.308298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.837665</td>\n",
       "      <td>-0.432228</td>\n",
       "      <td>-0.860039</td>\n",
       "      <td>-1.162721</td>\n",
       "      <td>-0.230683</td>\n",
       "      <td>-0.618422</td>\n",
       "      <td>1.264463</td>\n",
       "      <td>-0.513555</td>\n",
       "      <td>-0.820689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911435</td>\n",
       "      <td>1.622636</td>\n",
       "      <td>-0.289647</td>\n",
       "      <td>-0.155686</td>\n",
       "      <td>0.044143</td>\n",
       "      <td>0.095038</td>\n",
       "      <td>1.264463</td>\n",
       "      <td>0.236737</td>\n",
       "      <td>-1.149165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.964209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163010</td>\n",
       "      <td>-1.295827</td>\n",
       "      <td>1.631637</td>\n",
       "      <td>1.579494</td>\n",
       "      <td>-0.269583</td>\n",
       "      <td>-0.884526</td>\n",
       "      <td>0.121871</td>\n",
       "      <td>-2.064039</td>\n",
       "      <td>0.677176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.542635</td>\n",
       "      <td>-1.182758</td>\n",
       "      <td>1.767734</td>\n",
       "      <td>-0.877217</td>\n",
       "      <td>0.770980</td>\n",
       "      <td>-2.082843</td>\n",
       "      <td>-1.732896</td>\n",
       "      <td>-0.252844</td>\n",
       "      <td>0.052325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.852595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199897</td>\n",
       "      <td>0.068703</td>\n",
       "      <td>0.269125</td>\n",
       "      <td>-0.520476</td>\n",
       "      <td>0.556008</td>\n",
       "      <td>0.267558</td>\n",
       "      <td>-0.870682</td>\n",
       "      <td>0.236737</td>\n",
       "      <td>1.908137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.555951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.255256</td>\n",
       "      <td>0.166017</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.270944</td>\n",
       "      <td>-1.019210</td>\n",
       "      <td>-0.466233</td>\n",
       "      <td>0.121871</td>\n",
       "      <td>-0.252844</td>\n",
       "      <td>-0.365006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.631727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262086</td>\n",
       "      <td>0.068703</td>\n",
       "      <td>0.434620</td>\n",
       "      <td>0.717576</td>\n",
       "      <td>-0.211199</td>\n",
       "      <td>0.824915</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>-0.513555</td>\n",
       "      <td>0.312020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.084297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199897</td>\n",
       "      <td>-0.535590</td>\n",
       "      <td>2.109761</td>\n",
       "      <td>0.415731</td>\n",
       "      <td>1.409203</td>\n",
       "      <td>1.521413</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.468029</td>\n",
       "      <td>-0.512328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.487692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.682709</td>\n",
       "      <td>-1.071323</td>\n",
       "      <td>0.564164</td>\n",
       "      <td>-0.540002</td>\n",
       "      <td>-1.000673</td>\n",
       "      <td>-1.535760</td>\n",
       "      <td>-0.307098</td>\n",
       "      <td>0.236737</td>\n",
       "      <td>0.436838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.596176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.729847</td>\n",
       "      <td>-0.961425</td>\n",
       "      <td>1.235848</td>\n",
       "      <td>0.270944</td>\n",
       "      <td>0.822524</td>\n",
       "      <td>-0.567102</td>\n",
       "      <td>1.031663</td>\n",
       "      <td>0.236737</td>\n",
       "      <td>0.312020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138198</td>\n",
       "      <td>1.361887</td>\n",
       "      <td>-0.474340</td>\n",
       "      <td>0.216181</td>\n",
       "      <td>-1.285401</td>\n",
       "      <td>-0.130312</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.908147</td>\n",
       "      <td>-2.498840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.789011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.844222</td>\n",
       "      <td>0.732678</td>\n",
       "      <td>-0.820431</td>\n",
       "      <td>0.770046</td>\n",
       "      <td>0.123475</td>\n",
       "      <td>-0.567102</td>\n",
       "      <td>-0.870682</td>\n",
       "      <td>0.908147</td>\n",
       "      <td>2.084917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.322037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.116168</td>\n",
       "      <td>-0.432228</td>\n",
       "      <td>-0.703026</td>\n",
       "      <td>-0.042862</td>\n",
       "      <td>0.678550</td>\n",
       "      <td>0.710994</td>\n",
       "      <td>-1.732896</td>\n",
       "      <td>0.468029</td>\n",
       "      <td>1.333006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.137737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163010</td>\n",
       "      <td>-0.128676</td>\n",
       "      <td>0.401843</td>\n",
       "      <td>1.789632</td>\n",
       "      <td>2.791487</td>\n",
       "      <td>0.594218</td>\n",
       "      <td>1.031663</td>\n",
       "      <td>2.090856</td>\n",
       "      <td>0.677176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.617757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043976</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>-0.511906</td>\n",
       "      <td>-0.998685</td>\n",
       "      <td>0.444379</td>\n",
       "      <td>0.138787</td>\n",
       "      <td>-0.870682</td>\n",
       "      <td>-1.075340</td>\n",
       "      <td>-0.365006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.936834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.996003</td>\n",
       "      <td>-0.432228</td>\n",
       "      <td>0.269125</td>\n",
       "      <td>0.594227</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>1.925528</td>\n",
       "      <td>-0.307098</td>\n",
       "      <td>-0.787002</td>\n",
       "      <td>-1.149165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.325587</td>\n",
       "      <td>-1.527310</td>\n",
       "      <td>0.596168</td>\n",
       "      <td>0.451649</td>\n",
       "      <td>0.353547</td>\n",
       "      <td>-1.600293</td>\n",
       "      <td>-0.870682</td>\n",
       "      <td>0.691583</td>\n",
       "      <td>0.906024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.461904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.564688</td>\n",
       "      <td>-2.015649</td>\n",
       "      <td>0.596168</td>\n",
       "      <td>1.332385</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>-1.227262</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.468029</td>\n",
       "      <td>-0.221934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.489372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.995042</td>\n",
       "      <td>0.824510</td>\n",
       "      <td>-1.529112</td>\n",
       "      <td>-1.778543</td>\n",
       "      <td>-1.000673</td>\n",
       "      <td>1.220510</td>\n",
       "      <td>-1.732896</td>\n",
       "      <td>0.236737</td>\n",
       "      <td>-1.149165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-2.256817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.300683</td>\n",
       "      <td>-1.410638</td>\n",
       "      <td>-2.478298</td>\n",
       "      <td>0.142759</td>\n",
       "      <td>-1.394124</td>\n",
       "      <td>-0.567102</td>\n",
       "      <td>0.121871</td>\n",
       "      <td>-0.252844</td>\n",
       "      <td>0.183904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.226825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163010</td>\n",
       "      <td>0.546878</td>\n",
       "      <td>-1.102893</td>\n",
       "      <td>-1.519540</td>\n",
       "      <td>0.193184</td>\n",
       "      <td>0.309686</td>\n",
       "      <td>-0.870682</td>\n",
       "      <td>-1.075340</td>\n",
       "      <td>-1.149165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.356235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.675253</td>\n",
       "      <td>-0.535590</td>\n",
       "      <td>0.908214</td>\n",
       "      <td>1.725362</td>\n",
       "      <td>0.034252</td>\n",
       "      <td>-1.109925</td>\n",
       "      <td>1.031663</td>\n",
       "      <td>2.090856</td>\n",
       "      <td>0.558509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.298863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.844222</td>\n",
       "      <td>0.732678</td>\n",
       "      <td>-0.860039</td>\n",
       "      <td>-0.117955</td>\n",
       "      <td>-0.916971</td>\n",
       "      <td>0.514700</td>\n",
       "      <td>1.264463</td>\n",
       "      <td>1.521828</td>\n",
       "      <td>-0.221934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.865849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911435</td>\n",
       "      <td>1.536265</td>\n",
       "      <td>-0.181252</td>\n",
       "      <td>0.487457</td>\n",
       "      <td>0.576376</td>\n",
       "      <td>1.865486</td>\n",
       "      <td>-0.870682</td>\n",
       "      <td>0.236737</td>\n",
       "      <td>0.183904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.725080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.837665</td>\n",
       "      <td>0.452861</td>\n",
       "      <td>-0.399842</td>\n",
       "      <td>-0.717273</td>\n",
       "      <td>0.729845</td>\n",
       "      <td>0.050861</td>\n",
       "      <td>-0.870682</td>\n",
       "      <td>-1.381412</td>\n",
       "      <td>-0.221934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.281152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043976</td>\n",
       "      <td>1.622636</td>\n",
       "      <td>0.877642</td>\n",
       "      <td>-1.498230</td>\n",
       "      <td>0.283212</td>\n",
       "      <td>0.672394</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>-2.064039</td>\n",
       "      <td>-0.982264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2         3         4         5         6         7   \\\n",
       "0   0.962544  0.0  0.0  1.685188  1.006150 -0.741927 -1.605198 -2.550612   \n",
       "1   0.298863  0.0  0.0  0.138198  1.185227 -0.109958 -0.462096  0.093683   \n",
       "2  -0.312105  0.0  0.0  1.907385 -0.228819 -0.664354  1.232098 -0.935611   \n",
       "3  -1.308298  0.0  0.0 -0.837665 -0.432228 -0.860039 -1.162721 -0.230683   \n",
       "4   0.137737  0.0  0.0  0.911435  1.622636 -0.289647 -0.155686  0.044143   \n",
       "5   1.964209  0.0  0.0 -0.163010 -1.295827  1.631637  1.579494 -0.269583   \n",
       "6   0.698146  0.0  0.0 -1.542635 -1.182758  1.767734 -0.877217  0.770980   \n",
       "7  -0.852595  0.0  0.0  0.199897  0.068703  0.269125 -0.520476  0.556008   \n",
       "8   1.555951  0.0  0.0  1.255256  0.166017  0.065014  0.270944 -1.019210   \n",
       "9   1.631727  0.0  0.0  0.262086  0.068703  0.434620  0.717576 -0.211199   \n",
       "10  1.084297  0.0  0.0  0.199897 -0.535590  2.109761  0.415731  1.409203   \n",
       "11 -0.487692  0.0  0.0 -1.682709 -1.071323  0.564164 -0.540002 -1.000673   \n",
       "12 -0.596176  0.0  0.0 -0.729847 -0.961425  1.235848  0.270944  0.822524   \n",
       "13  0.252632  0.0  0.0  0.138198  1.361887 -0.474340  0.216181 -1.285401   \n",
       "14 -0.789011  0.0  0.0  0.844222  0.732678 -0.820431  0.770046  0.123475   \n",
       "15  0.322037  0.0  0.0  1.116168 -0.432228 -0.703026 -0.042862  0.678550   \n",
       "16  0.137737  0.0  0.0 -0.163010 -0.128676  0.401843  1.789632  2.791487   \n",
       "17 -0.617757  0.0  0.0 -0.043976  0.262460 -0.511906 -0.998685  0.444379   \n",
       "18 -0.936834  0.0  0.0 -0.996003 -0.432228  0.269125  0.594227  0.004612   \n",
       "19  0.001150  0.0  0.0  1.325587 -1.527310  0.596168  0.451649  0.353547   \n",
       "20  0.461904  0.0  0.0 -0.564688 -2.015649  0.596168  1.332385  0.905280   \n",
       "21 -1.489372  0.0  0.0 -1.995042  0.824510 -1.529112 -1.778543 -1.000673   \n",
       "22 -2.256817  0.0  0.0 -1.300683 -1.410638 -2.478298  0.142759 -1.394124   \n",
       "23 -1.226825  0.0  0.0 -0.163010  0.546878 -1.102893 -1.519540  0.193184   \n",
       "24 -0.356235  0.0  0.0 -0.675253 -0.535590  0.908214  1.725362  0.034252   \n",
       "25  0.298863  0.0  0.0  0.844222  0.732678 -0.860039 -0.117955 -0.916971   \n",
       "26  0.865849  0.0  0.0  0.911435  1.536265 -0.181252  0.487457  0.576376   \n",
       "27 -0.725080  0.0  0.0 -0.837665  0.452861 -0.399842 -0.717273  0.729845   \n",
       "28  1.281152  0.0  0.0 -0.043976  1.622636  0.877642 -1.498230  0.283212   \n",
       "\n",
       "          8         9         10        11  \n",
       "0   0.936132 -0.307098 -0.787002  1.532753  \n",
       "1  -0.516377 -0.307098  0.236737  0.312020  \n",
       "2   0.225038  2.011315 -0.252844 -0.664137  \n",
       "3  -0.618422  1.264463 -0.513555 -0.820689  \n",
       "4   0.095038  1.264463  0.236737 -1.149165  \n",
       "5  -0.884526  0.121871 -2.064039  0.677176  \n",
       "6  -2.082843 -1.732896 -0.252844  0.052325  \n",
       "7   0.267558 -0.870682  0.236737  1.908137  \n",
       "8  -0.466233  0.121871 -0.252844 -0.365006  \n",
       "9   0.824915  0.770649 -0.513555  0.312020  \n",
       "10  1.521413  0.770649  0.468029 -0.512328  \n",
       "11 -1.535760 -0.307098  0.236737  0.436838  \n",
       "12 -0.567102  1.031663  0.236737  0.312020  \n",
       "13 -0.130312  0.770649  0.908147 -2.498840  \n",
       "14 -0.567102 -0.870682  0.908147  2.084917  \n",
       "15  0.710994 -1.732896  0.468029  1.333006  \n",
       "16  0.594218  1.031663  2.090856  0.677176  \n",
       "17  0.138787 -0.870682 -1.075340 -0.365006  \n",
       "18  1.925528 -0.307098 -0.787002 -1.149165  \n",
       "19 -1.600293 -0.870682  0.691583  0.906024  \n",
       "20 -1.227262  0.472300  0.468029 -0.221934  \n",
       "21  1.220510 -1.732896  0.236737 -1.149165  \n",
       "22 -0.567102  0.121871 -0.252844  0.183904  \n",
       "23  0.309686 -0.870682 -1.075340 -1.149165  \n",
       "24 -1.109925  1.031663  2.090856  0.558509  \n",
       "25  0.514700  1.264463  1.521828 -0.221934  \n",
       "26  1.865486 -0.870682  0.236737  0.183904  \n",
       "27  0.050861 -0.870682 -1.381412 -0.221934  \n",
       "28  0.672394  0.472300 -2.064039 -0.982264  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_x\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.62543504e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.68518793e+00,  1.00615029e+00, -7.41927000e-01,\n",
       "        -1.60519802e+00, -2.55061247e+00,  9.36131648e-01,\n",
       "        -3.07098204e-01, -7.87002186e-01,  1.53275292e+00],\n",
       "       [ 2.98863300e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.38197902e-01,  1.18522654e+00, -1.09958425e-01,\n",
       "        -4.62095966e-01,  9.36832915e-02, -5.16377335e-01,\n",
       "        -3.07098204e-01,  2.36736538e-01,  3.12020186e-01],\n",
       "       [-3.12105130e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.90738550e+00, -2.28819392e-01, -6.64354121e-01,\n",
       "         1.23209786e+00, -9.35611465e-01,  2.25038365e-01,\n",
       "         2.01131531e+00, -2.52844176e-01, -6.64136739e-01],\n",
       "       [-1.30829774e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -8.37664770e-01, -4.32227907e-01, -8.60039342e-01,\n",
       "        -1.16272085e+00, -2.30682707e-01, -6.18421529e-01,\n",
       "         1.26446344e+00, -5.13554932e-01, -8.20688859e-01],\n",
       "       [ 1.37737301e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         9.11434794e-01,  1.62263592e+00, -2.89646675e-01,\n",
       "        -1.55685826e-01,  4.41433307e-02,  9.50377681e-02,\n",
       "         1.26446344e+00,  2.36736538e-01, -1.14916472e+00],\n",
       "       [ 1.96420873e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.63010220e-01, -1.29582738e+00,  1.63163749e+00,\n",
       "         1.57949358e+00, -2.69582692e-01, -8.84525554e-01,\n",
       "         1.21870592e-01, -2.06403920e+00,  6.77176215e-01],\n",
       "       [ 6.98145564e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.54263548e+00, -1.18275843e+00,  1.76773356e+00,\n",
       "        -8.77216697e-01,  7.70980104e-01, -2.08284252e+00,\n",
       "        -1.73289617e+00, -2.52844176e-01,  5.23253489e-02],\n",
       "       [-8.52595277e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.99896614e-01,  6.87034881e-02,  2.69125303e-01,\n",
       "        -5.20475583e-01,  5.56007529e-01,  2.67558365e-01,\n",
       "        -8.70681710e-01,  2.36736538e-01,  1.90813725e+00],\n",
       "       [ 1.55595108e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.25525640e+00,  1.66016920e-01,  6.50138601e-02,\n",
       "         2.70943885e-01, -1.01920973e+00, -4.66233050e-01,\n",
       "         1.21870592e-01, -2.52844176e-01, -3.65006331e-01],\n",
       "       [ 1.63172674e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.62085981e-01,  6.87034881e-02,  4.34619901e-01,\n",
       "         7.17575787e-01, -2.11198815e-01,  8.24915052e-01,\n",
       "         7.70648979e-01, -5.13554932e-01,  3.12020186e-01],\n",
       "       [ 1.08429715e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.99896614e-01, -5.35589865e-01,  2.10976140e+00,\n",
       "         4.15731318e-01,  1.40920289e+00,  1.52141342e+00,\n",
       "         7.70648979e-01,  4.68029391e-01, -5.12328248e-01],\n",
       "       [-4.87692420e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.68270914e+00, -1.07132315e+00,  5.64164281e-01,\n",
       "        -5.40002291e-01, -1.00067264e+00, -1.53576005e+00,\n",
       "        -3.07098204e-01,  2.36736538e-01,  4.36837705e-01],\n",
       "       [-5.96175935e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -7.29846682e-01, -9.61425202e-01,  1.23584791e+00,\n",
       "         2.70943885e-01,  8.22523572e-01, -5.67101779e-01,\n",
       "         1.03166276e+00,  2.36736538e-01,  3.12020186e-01],\n",
       "       [ 2.52632115e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.38197902e-01,  1.36188686e+00, -4.74339591e-01,\n",
       "         2.16180612e-01, -1.28540143e+00, -1.30311671e-01,\n",
       "         7.70648979e-01,  9.08147185e-01, -2.49883997e+00],\n",
       "       [-7.89011402e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.44221534e-01,  7.32678154e-01, -8.20430695e-01,\n",
       "         7.70046367e-01,  1.23474558e-01, -5.67101779e-01,\n",
       "        -8.70681710e-01,  9.08147185e-01,  2.08491727e+00],\n",
       "       [ 3.22037487e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.11616810e+00, -4.32227907e-01, -7.03025726e-01,\n",
       "        -4.28617534e-02,  6.78550021e-01,  7.10994061e-01,\n",
       "        -1.73289617e+00,  4.68029391e-01,  1.33300631e+00],\n",
       "       [ 1.37737301e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.63010220e-01, -1.28676161e-01,  4.01843420e-01,\n",
       "         1.78963187e+00,  2.79148702e+00,  5.94217890e-01,\n",
       "         1.03166276e+00,  2.09085582e+00,  6.77176215e-01],\n",
       "       [-6.17756609e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -4.39755655e-02,  2.62459743e-01, -5.11906087e-01,\n",
       "        -9.98685266e-01,  4.44378919e-01,  1.38786720e-01,\n",
       "        -8.70681710e-01, -1.07533963e+00, -3.65006331e-01],\n",
       "       [-9.36834306e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -9.96002506e-01, -4.32227907e-01,  2.69125303e-01,\n",
       "         5.94226550e-01,  4.61238853e-03,  1.92552808e+00,\n",
       "        -3.07098204e-01, -7.87002186e-01, -1.14916472e+00],\n",
       "       [ 1.15032665e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.32558682e+00, -1.52730964e+00,  5.96168091e-01,\n",
       "         4.51648972e-01,  3.53547035e-01, -1.60029335e+00,\n",
       "        -8.70681710e-01,  6.91582693e-01,  9.06023678e-01],\n",
       "       [ 4.61903563e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -5.64688157e-01, -2.01564882e+00,  5.96168091e-01,\n",
       "         1.33238489e+00,  9.05280039e-01, -1.22726215e+00,\n",
       "         4.72300348e-01,  4.68029391e-01, -2.21933710e-01],\n",
       "       [-1.48937178e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.99504220e+00,  8.24510284e-01, -1.52911231e+00,\n",
       "        -1.77854272e+00, -1.00067264e+00,  1.22050964e+00,\n",
       "        -1.73289617e+00,  2.36736538e-01, -1.14916472e+00],\n",
       "       [-2.25681725e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.30068346e+00, -1.41063754e+00, -2.47829793e+00,\n",
       "         1.42758514e-01, -1.39412379e+00, -5.67101779e-01,\n",
       "         1.21870592e-01, -2.52844176e-01,  1.83903886e-01],\n",
       "       [-1.22682499e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.63010220e-01,  5.46877831e-01, -1.10289298e+00,\n",
       "        -1.51954034e+00,  1.93183556e-01,  3.09685564e-01,\n",
       "        -8.70681710e-01, -1.07533963e+00, -1.14916472e+00],\n",
       "       [-3.56234524e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -6.75253462e-01, -5.35589865e-01,  9.08214214e-01,\n",
       "         1.72536184e+00,  3.42521724e-02, -1.10992538e+00,\n",
       "         1.03166276e+00,  2.09085582e+00,  5.58508906e-01],\n",
       "       [ 2.98863300e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.44221534e-01,  7.32678154e-01, -8.60039342e-01,\n",
       "        -1.17954659e-01, -9.16970789e-01,  5.14700397e-01,\n",
       "         1.26446344e+00,  1.52182832e+00, -2.21933710e-01],\n",
       "       [ 8.65848732e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         9.11434794e-01,  1.53626470e+00, -1.81252234e-01,\n",
       "         4.87456542e-01,  5.76375836e-01,  1.86548585e+00,\n",
       "        -8.70681710e-01,  2.36736538e-01,  1.83903886e-01],\n",
       "       [-7.25080407e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -8.37664770e-01,  4.52860860e-01, -3.99842255e-01,\n",
       "        -7.17272959e-01,  7.29844768e-01,  5.08613716e-02,\n",
       "        -8.70681710e-01, -1.38141238e+00, -2.21933710e-01],\n",
       "       [ 1.28115156e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -4.39755655e-02,  1.62263592e+00,  8.77641898e-01,\n",
       "        -1.49822954e+00,  2.83212126e-01,  6.72393731e-01,\n",
       "         4.72300348e-01, -2.06403920e+00, -9.82263658e-01]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Best random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random State : 1 and Train R2 Score : 0.8550783206268826\n",
      "Best Random State : 1 and Test R2 Score : 0.6944530201712394\n",
      "\n",
      "Best Random State : 2 and Train R2 Score : 0.8173961865951549\n",
      "Best Random State : 2 and Test R2 Score : -0.8302730889884651\n",
      "\n",
      "Best Random State : 3 and Train R2 Score : 0.8199055316941919\n",
      "Best Random State : 3 and Test R2 Score : 0.7257992916491386\n",
      "\n",
      "Best Random State : 4 and Train R2 Score : 0.8536067232046677\n",
      "Best Random State : 4 and Test R2 Score : 0.618508188589969\n",
      "\n",
      "Best Random State : 5 and Train R2 Score : 0.8806333789341638\n",
      "Best Random State : 5 and Test R2 Score : 0.2671195820874026\n",
      "\n",
      "Best Random State : 6 and Train R2 Score : 0.8800922107276878\n",
      "Best Random State : 6 and Test R2 Score : 0.6629688959955353\n",
      "\n",
      "Best Random State : 7 and Train R2 Score : 0.8488482103041881\n",
      "Best Random State : 7 and Test R2 Score : 0.38500783612986544\n",
      "\n",
      "Best Random State : 8 and Train R2 Score : 0.8368074421041336\n",
      "Best Random State : 8 and Test R2 Score : 0.7888158307008533\n",
      "\n",
      "Best Random State : 9 and Train R2 Score : 0.8917311638958252\n",
      "Best Random State : 9 and Test R2 Score : 0.5015820827822994\n",
      "\n",
      "Best Random State : 10 and Train R2 Score : 0.9399508558275093\n",
      "Best Random State : 10 and Test R2 Score : -0.5117016785315369\n",
      "\n",
      "Best Random State : 11 and Train R2 Score : 0.9109079921055049\n",
      "Best Random State : 11 and Test R2 Score : 0.04886409060758801\n",
      "\n",
      "Best Random State : 12 and Train R2 Score : 0.8919471790057252\n",
      "Best Random State : 12 and Test R2 Score : 0.279779827412021\n",
      "\n",
      "Best Random State : 13 and Train R2 Score : 0.9053501069448884\n",
      "Best Random State : 13 and Test R2 Score : 0.2739711385038096\n",
      "\n",
      "Best Random State : 14 and Train R2 Score : 0.8691195909657863\n",
      "Best Random State : 14 and Test R2 Score : 0.37015927849115493\n",
      "\n",
      "Best Random State : 15 and Train R2 Score : 0.8385272576483469\n",
      "Best Random State : 15 and Test R2 Score : 0.5735333444312216\n",
      "\n",
      "Best Random State : 16 and Train R2 Score : 0.935853543356118\n",
      "Best Random State : 16 and Test R2 Score : -0.9249951418951803\n",
      "\n",
      "Best Random State : 17 and Train R2 Score : 0.8655760431957599\n",
      "Best Random State : 17 and Test R2 Score : 0.3767337015737824\n",
      "\n",
      "Best Random State : 18 and Train R2 Score : 0.846495918972922\n",
      "Best Random State : 18 and Test R2 Score : 0.533030691637931\n",
      "\n",
      "Best Random State : 19 and Train R2 Score : 0.8222691415919189\n",
      "Best Random State : 19 and Test R2 Score : 0.6766541512739409\n",
      "\n",
      "Best Random State : 20 and Train R2 Score : 0.8125292391448938\n",
      "Best Random State : 20 and Test R2 Score : 0.7647327631733324\n",
      "\n",
      "Best Random State : 21 and Train R2 Score : 0.9074770068752576\n",
      "Best Random State : 21 and Test R2 Score : 0.2100026164665446\n",
      "\n",
      "Best Random State : 22 and Train R2 Score : 0.8582939935980882\n",
      "Best Random State : 22 and Test R2 Score : 0.0861660247936954\n",
      "\n",
      "Best Random State : 23 and Train R2 Score : 0.8273528079101595\n",
      "Best Random State : 23 and Test R2 Score : 0.7812319076407748\n",
      "\n",
      "Best Random State : 24 and Train R2 Score : 0.8724832534231717\n",
      "Best Random State : 24 and Test R2 Score : 0.21676545671501357\n",
      "\n",
      "Best Random State : 25 and Train R2 Score : 0.8585981307323539\n",
      "Best Random State : 25 and Test R2 Score : 0.006513845670277907\n",
      "\n",
      "Best Random State : 26 and Train R2 Score : 0.8480002958260073\n",
      "Best Random State : 26 and Test R2 Score : 0.7275287921966042\n",
      "\n",
      "Best Random State : 27 and Train R2 Score : 0.9211873672519363\n",
      "Best Random State : 27 and Test R2 Score : 0.3819650377364717\n",
      "\n",
      "Best Random State : 28 and Train R2 Score : 0.825104563374699\n",
      "Best Random State : 28 and Test R2 Score : 0.6905298962669619\n",
      "\n",
      "Best Random State : 29 and Train R2 Score : 0.9113531542230844\n",
      "Best Random State : 29 and Test R2 Score : -0.005520563302800596\n",
      "\n",
      "Best Random State : 30 and Train R2 Score : 0.8509857432705106\n",
      "Best Random State : 30 and Test R2 Score : 0.7298073228638462\n",
      "\n",
      "Best Random State : 31 and Train R2 Score : 0.8992425996806522\n",
      "Best Random State : 31 and Test R2 Score : -0.3771636064858974\n",
      "\n",
      "Best Random State : 32 and Train R2 Score : 0.8113832716700266\n",
      "Best Random State : 32 and Test R2 Score : 0.7138272942200866\n",
      "\n",
      "Best Random State : 33 and Train R2 Score : 0.8407516011064431\n",
      "Best Random State : 33 and Test R2 Score : 0.6247527573569971\n",
      "\n",
      "Best Random State : 34 and Train R2 Score : 0.8845358348699612\n",
      "Best Random State : 34 and Test R2 Score : 0.4113891940628407\n",
      "\n",
      "Best Random State : 35 and Train R2 Score : 0.8479990119190491\n",
      "Best Random State : 35 and Test R2 Score : 0.6952731772939857\n",
      "\n",
      "Best Random State : 36 and Train R2 Score : 0.8763162839564113\n",
      "Best Random State : 36 and Test R2 Score : 0.13325251860845788\n",
      "\n",
      "Best Random State : 37 and Train R2 Score : 0.9228618632322305\n",
      "Best Random State : 37 and Test R2 Score : -1.5010519483247822\n",
      "\n",
      "Best Random State : 38 and Train R2 Score : 0.865249757405706\n",
      "Best Random State : 38 and Test R2 Score : 0.07773460899225271\n",
      "\n",
      "Best Random State : 39 and Train R2 Score : 0.950924251758532\n",
      "Best Random State : 39 and Test R2 Score : -0.40382510738990307\n",
      "\n",
      "Best Random State : 40 and Train R2 Score : 0.8622524005224338\n",
      "Best Random State : 40 and Test R2 Score : 0.0006886398666685611\n",
      "\n",
      "Best Random State : 41 and Train R2 Score : 0.9075199228855131\n",
      "Best Random State : 41 and Test R2 Score : 0.07243207073290969\n",
      "\n",
      "Best Random State : 42 and Train R2 Score : 0.8972340750602206\n",
      "Best Random State : 42 and Test R2 Score : 0.4655335864386736\n",
      "\n",
      "Best Random State : 43 and Train R2 Score : 0.9122987943396819\n",
      "Best Random State : 43 and Test R2 Score : -0.6141752546182455\n",
      "\n",
      "Best Random State : 44 and Train R2 Score : 0.8937411996023863\n",
      "Best Random State : 44 and Test R2 Score : 0.4056298944519645\n",
      "\n",
      "Best Random State : 45 and Train R2 Score : 0.9182495520421918\n",
      "Best Random State : 45 and Test R2 Score : 0.2342639590114789\n",
      "\n",
      "Best Random State : 46 and Train R2 Score : 0.853071343704793\n",
      "Best Random State : 46 and Test R2 Score : 0.7043489488388694\n",
      "\n",
      "Best Random State : 47 and Train R2 Score : 0.8743188165183928\n",
      "Best Random State : 47 and Test R2 Score : 0.4345159313889392\n",
      "\n",
      "Best Random State : 48 and Train R2 Score : 0.8938482300260655\n",
      "Best Random State : 48 and Test R2 Score : 0.22262955981972232\n",
      "\n",
      "Best Random State : 49 and Train R2 Score : 0.8577760669875534\n",
      "Best Random State : 49 and Test R2 Score : -0.33603735503657384\n",
      "\n",
      "Best Random State : 50 and Train R2 Score : 0.8221150674672104\n",
      "Best Random State : 50 and Test R2 Score : 0.7939594551235089\n",
      "\n",
      "Best Random State : 51 and Train R2 Score : 0.9359599575529464\n",
      "Best Random State : 51 and Test R2 Score : 0.33857669943364366\n",
      "\n",
      "Best Random State : 52 and Train R2 Score : 0.9378397365348585\n",
      "Best Random State : 52 and Test R2 Score : -0.44847753780789157\n",
      "\n",
      "Best Random State : 53 and Train R2 Score : 0.8209278153298687\n",
      "Best Random State : 53 and Test R2 Score : 0.7708039490333244\n",
      "\n",
      "Best Random State : 54 and Train R2 Score : 0.9235567252009229\n",
      "Best Random State : 54 and Test R2 Score : -1.9173875187876481\n",
      "\n",
      "Best Random State : 55 and Train R2 Score : 0.8752906481057526\n",
      "Best Random State : 55 and Test R2 Score : -0.22644840952080902\n",
      "\n",
      "Best Random State : 56 and Train R2 Score : 0.8925893895130531\n",
      "Best Random State : 56 and Test R2 Score : 0.3371416525297586\n",
      "\n",
      "Best Random State : 57 and Train R2 Score : 0.872644164983993\n",
      "Best Random State : 57 and Test R2 Score : 0.6611362147488559\n",
      "\n",
      "Best Random State : 58 and Train R2 Score : 0.8660366574270222\n",
      "Best Random State : 58 and Test R2 Score : 0.5403932960169411\n",
      "\n",
      "Best Random State : 59 and Train R2 Score : 0.8818416438921528\n",
      "Best Random State : 59 and Test R2 Score : 0.594270386521398\n",
      "\n",
      "Best Random State : 60 and Train R2 Score : 0.8628703276962643\n",
      "Best Random State : 60 and Test R2 Score : 0.5813479554115253\n",
      "\n",
      "Best Random State : 61 and Train R2 Score : 0.9009033464069783\n",
      "Best Random State : 61 and Test R2 Score : 0.6143880780288759\n",
      "\n",
      "Best Random State : 62 and Train R2 Score : 0.900777229372422\n",
      "Best Random State : 62 and Test R2 Score : 0.37017952259918463\n",
      "\n",
      "Best Random State : 63 and Train R2 Score : 0.9292353833605903\n",
      "Best Random State : 63 and Test R2 Score : 0.1983940924871076\n",
      "\n",
      "Best Random State : 64 and Train R2 Score : 0.8771248260411929\n",
      "Best Random State : 64 and Test R2 Score : 0.4879644094325689\n",
      "\n",
      "Best Random State : 65 and Train R2 Score : 0.8219625386213906\n",
      "Best Random State : 65 and Test R2 Score : 0.8230465266163549\n",
      "\n",
      "Best Random State : 66 and Train R2 Score : 0.8598322028068799\n",
      "Best Random State : 66 and Test R2 Score : 0.5499512978604322\n",
      "\n",
      "Best Random State : 67 and Train R2 Score : 0.8212383732694155\n",
      "Best Random State : 67 and Test R2 Score : 0.7117124279740379\n",
      "\n",
      "Best Random State : 68 and Train R2 Score : 0.8850955057193273\n",
      "Best Random State : 68 and Test R2 Score : 0.24391723715352298\n",
      "\n",
      "Best Random State : 69 and Train R2 Score : 0.8603590614864745\n",
      "Best Random State : 69 and Test R2 Score : 0.30876715043383773\n",
      "\n",
      "Best Random State : 70 and Train R2 Score : 0.8462734437420445\n",
      "Best Random State : 70 and Test R2 Score : 0.7368116272479813\n",
      "\n",
      "Best Random State : 71 and Train R2 Score : 0.9319856237676133\n",
      "Best Random State : 71 and Test R2 Score : -1.5093641421941206\n",
      "\n",
      "Best Random State : 72 and Train R2 Score : 0.9206777248261397\n",
      "Best Random State : 72 and Test R2 Score : -2.240355265080324\n",
      "\n",
      "Best Random State : 73 and Train R2 Score : 0.8390618218119078\n",
      "Best Random State : 73 and Test R2 Score : 0.6052614463854136\n",
      "\n",
      "Best Random State : 74 and Train R2 Score : 0.8785955234554571\n",
      "Best Random State : 74 and Test R2 Score : -0.20040274232274768\n",
      "\n",
      "Best Random State : 75 and Train R2 Score : 0.8612262526998183\n",
      "Best Random State : 75 and Test R2 Score : 0.696393330684543\n",
      "\n",
      "Best Random State : 76 and Train R2 Score : 0.7891174651749291\n",
      "Best Random State : 76 and Test R2 Score : 0.9185290272722267\n",
      "\n",
      "Best Random State : 77 and Train R2 Score : 0.8730794224700524\n",
      "Best Random State : 77 and Test R2 Score : 0.5883556242844419\n",
      "\n",
      "Best Random State : 78 and Train R2 Score : 0.8466216932658616\n",
      "Best Random State : 78 and Test R2 Score : 0.5394527863583266\n",
      "\n",
      "Best Random State : 79 and Train R2 Score : 0.9113677258593144\n",
      "Best Random State : 79 and Test R2 Score : 0.4959225177351756\n",
      "\n",
      "Best Random State : 80 and Train R2 Score : 0.8767851985771222\n",
      "Best Random State : 80 and Test R2 Score : 0.22999162003212725\n",
      "\n",
      "Best Random State : 81 and Train R2 Score : 0.8859066001189972\n",
      "Best Random State : 81 and Test R2 Score : 0.35856130175797274\n",
      "\n",
      "Best Random State : 82 and Train R2 Score : 0.8826854468714793\n",
      "Best Random State : 82 and Test R2 Score : 0.13199465765239382\n",
      "\n",
      "Best Random State : 83 and Train R2 Score : 0.8667594479683031\n",
      "Best Random State : 83 and Test R2 Score : 0.40609453812244756\n",
      "\n",
      "Best Random State : 84 and Train R2 Score : 0.9385810541067555\n",
      "Best Random State : 84 and Test R2 Score : -0.9716437638836133\n",
      "\n",
      "Best Random State : 85 and Train R2 Score : 0.8881377549571116\n",
      "Best Random State : 85 and Test R2 Score : 0.46611880439301345\n",
      "\n",
      "Best Random State : 86 and Train R2 Score : 0.8462651825975334\n",
      "Best Random State : 86 and Test R2 Score : 0.045977822869128326\n",
      "\n",
      "Best Random State : 87 and Train R2 Score : 0.863487733195145\n",
      "Best Random State : 87 and Test R2 Score : -0.1654727883772955\n",
      "\n",
      "Best Random State : 88 and Train R2 Score : 0.9475429118596443\n",
      "Best Random State : 88 and Test R2 Score : -2.251177652819797\n",
      "\n",
      "Best Random State : 89 and Train R2 Score : 0.8591789211440064\n",
      "Best Random State : 89 and Test R2 Score : 0.6097641626791959\n",
      "\n",
      "Best Random State : 90 and Train R2 Score : 0.8658939087991939\n",
      "Best Random State : 90 and Test R2 Score : 0.4581525944679886\n",
      "\n",
      "Best Random State : 91 and Train R2 Score : 0.9190492185868503\n",
      "Best Random State : 91 and Test R2 Score : 0.2914966821441669\n",
      "\n",
      "Best Random State : 92 and Train R2 Score : 0.9218933139577338\n",
      "Best Random State : 92 and Test R2 Score : -0.3099011382308252\n",
      "\n",
      "Best Random State : 93 and Train R2 Score : 0.9143576037314245\n",
      "Best Random State : 93 and Test R2 Score : -1.9595624512009304\n",
      "\n",
      "Best Random State : 94 and Train R2 Score : 0.8534758340216136\n",
      "Best Random State : 94 and Test R2 Score : 0.42939349008035055\n",
      "\n",
      "Best Random State : 95 and Train R2 Score : 0.841616472500125\n",
      "Best Random State : 95 and Test R2 Score : 0.47510350162883075\n",
      "\n",
      "Best Random State : 96 and Train R2 Score : 0.8273151225809028\n",
      "Best Random State : 96 and Test R2 Score : 0.7375169410944531\n",
      "\n",
      "Best Random State : 97 and Train R2 Score : 0.8236368488127326\n",
      "Best Random State : 97 and Test R2 Score : 0.7442204371428514\n",
      "\n",
      "Best Random State : 98 and Train R2 Score : 0.8611976511495218\n",
      "Best Random State : 98 and Test R2 Score : 0.2898364888501479\n",
      "\n",
      "Best Random State : 99 and Train R2 Score : 0.9103533412329969\n",
      "Best Random State : 99 and Test R2 Score : -0.14095624408519147\n",
      "\n",
      "Best Random State : 100 and Train R2 Score : 0.9051726363086787\n",
      "Best Random State : 100 and Test R2 Score : -0.14178130445144999\n",
      "\n",
      "Best Random State : 101 and Train R2 Score : 0.9320306072637444\n",
      "Best Random State : 101 and Test R2 Score : 0.03495944911369342\n",
      "\n",
      "Best Random State : 102 and Train R2 Score : 0.8362828123333107\n",
      "Best Random State : 102 and Test R2 Score : 0.6402591736828424\n",
      "\n",
      "Best Random State : 103 and Train R2 Score : 0.9106456925696681\n",
      "Best Random State : 103 and Test R2 Score : 0.23959832123553915\n",
      "\n",
      "Best Random State : 104 and Train R2 Score : 0.8605537790107143\n",
      "Best Random State : 104 and Test R2 Score : 0.5923471073247888\n",
      "\n",
      "Best Random State : 105 and Train R2 Score : 0.9323376838018611\n",
      "Best Random State : 105 and Test R2 Score : -0.9943349524661138\n",
      "\n",
      "Best Random State : 106 and Train R2 Score : 0.8713058500254478\n",
      "Best Random State : 106 and Test R2 Score : 0.6438070062822191\n",
      "\n",
      "Best Random State : 107 and Train R2 Score : 0.928656092211921\n",
      "Best Random State : 107 and Test R2 Score : -0.7194596537313398\n",
      "\n",
      "Best Random State : 108 and Train R2 Score : 0.8211718732636343\n",
      "Best Random State : 108 and Test R2 Score : 0.4630147332150334\n",
      "\n",
      "Best Random State : 109 and Train R2 Score : 0.9699597269140463\n",
      "Best Random State : 109 and Test R2 Score : -1.3716294448441344\n",
      "\n",
      "Best Random State : 110 and Train R2 Score : 0.8669352047255485\n",
      "Best Random State : 110 and Test R2 Score : -0.11213970075066793\n",
      "\n",
      "Best Random State : 111 and Train R2 Score : 0.8561524731571144\n",
      "Best Random State : 111 and Test R2 Score : 0.5405745621433418\n",
      "\n",
      "Best Random State : 112 and Train R2 Score : 0.8514409217724965\n",
      "Best Random State : 112 and Test R2 Score : 0.332852250039515\n",
      "\n",
      "Best Random State : 113 and Train R2 Score : 0.8542831901293058\n",
      "Best Random State : 113 and Test R2 Score : -0.00864693121345983\n",
      "\n",
      "Best Random State : 114 and Train R2 Score : 0.840294180459868\n",
      "Best Random State : 114 and Test R2 Score : 0.7426749233119212\n",
      "\n",
      "Best Random State : 115 and Train R2 Score : 0.8838594063221887\n",
      "Best Random State : 115 and Test R2 Score : 0.20551561486177716\n",
      "\n",
      "Best Random State : 116 and Train R2 Score : 0.8066043614702\n",
      "Best Random State : 116 and Test R2 Score : 0.6946603354616834\n",
      "\n",
      "Best Random State : 117 and Train R2 Score : 0.9165797769595697\n",
      "Best Random State : 117 and Test R2 Score : 0.14599217072856807\n",
      "\n",
      "Best Random State : 118 and Train R2 Score : 0.8720949542137635\n",
      "Best Random State : 118 and Test R2 Score : 0.5299161502073328\n",
      "\n",
      "Best Random State : 119 and Train R2 Score : 0.8577174408959799\n",
      "Best Random State : 119 and Test R2 Score : 0.19234087190801064\n",
      "\n",
      "Best Random State : 120 and Train R2 Score : 0.9555502509305717\n",
      "Best Random State : 120 and Test R2 Score : -6.623442567459631\n",
      "\n",
      "Best Random State : 121 and Train R2 Score : 0.8256284472842839\n",
      "Best Random State : 121 and Test R2 Score : 0.67835166946569\n",
      "\n",
      "Best Random State : 122 and Train R2 Score : 0.8736907733430403\n",
      "Best Random State : 122 and Test R2 Score : 0.5293042914227689\n",
      "\n",
      "Best Random State : 123 and Train R2 Score : 0.9420276046388477\n",
      "Best Random State : 123 and Test R2 Score : -1.3695298753221996\n",
      "\n",
      "Best Random State : 124 and Train R2 Score : 0.9013001168048138\n",
      "Best Random State : 124 and Test R2 Score : -1.2906388317506745\n",
      "\n",
      "Best Random State : 125 and Train R2 Score : 0.8710465845396251\n",
      "Best Random State : 125 and Test R2 Score : 0.3519629255327109\n",
      "\n",
      "Best Random State : 126 and Train R2 Score : 0.9618240158128493\n",
      "Best Random State : 126 and Test R2 Score : -1.4222310926870816\n",
      "\n",
      "Best Random State : 127 and Train R2 Score : 0.9431920007497755\n",
      "Best Random State : 127 and Test R2 Score : -0.8629868946296435\n",
      "\n",
      "Best Random State : 128 and Train R2 Score : 0.9191975862328998\n",
      "Best Random State : 128 and Test R2 Score : 0.3618229254369264\n",
      "\n",
      "Best Random State : 129 and Train R2 Score : 0.8586998865513112\n",
      "Best Random State : 129 and Test R2 Score : 0.4829885568234281\n",
      "\n",
      "Best Random State : 130 and Train R2 Score : 0.8109508918414512\n",
      "Best Random State : 130 and Test R2 Score : 0.7457507110965598\n",
      "\n",
      "Best Random State : 131 and Train R2 Score : 0.9035751364333298\n",
      "Best Random State : 131 and Test R2 Score : 0.32443937189060823\n",
      "\n",
      "Best Random State : 132 and Train R2 Score : 0.8580691800675184\n",
      "Best Random State : 132 and Test R2 Score : 0.6678597155119175\n",
      "\n",
      "Best Random State : 133 and Train R2 Score : 0.8423652487020991\n",
      "Best Random State : 133 and Test R2 Score : 0.631432709507181\n",
      "\n",
      "Best Random State : 134 and Train R2 Score : 0.8663271678861246\n",
      "Best Random State : 134 and Test R2 Score : -0.5549618958617812\n",
      "\n",
      "Best Random State : 135 and Train R2 Score : 0.8611467960903209\n",
      "Best Random State : 135 and Test R2 Score : 0.33094861786401886\n",
      "\n",
      "Best Random State : 136 and Train R2 Score : 0.8780293116708738\n",
      "Best Random State : 136 and Test R2 Score : 0.28366538247648343\n",
      "\n",
      "Best Random State : 137 and Train R2 Score : 0.9437356754393428\n",
      "Best Random State : 137 and Test R2 Score : -0.0561273685869601\n",
      "\n",
      "Best Random State : 138 and Train R2 Score : 0.8502244320727739\n",
      "Best Random State : 138 and Test R2 Score : 0.5973036221320686\n",
      "\n",
      "Best Random State : 139 and Train R2 Score : 0.8713025336713577\n",
      "Best Random State : 139 and Test R2 Score : 0.4117204831190482\n",
      "\n",
      "Best Random State : 140 and Train R2 Score : 0.8374928646503409\n",
      "Best Random State : 140 and Test R2 Score : 0.8250910481974928\n",
      "\n",
      "Best Random State : 141 and Train R2 Score : 0.8666433371275284\n",
      "Best Random State : 141 and Test R2 Score : 0.6269756211251553\n",
      "\n",
      "Best Random State : 142 and Train R2 Score : 0.8323751725564186\n",
      "Best Random State : 142 and Test R2 Score : 0.7015833709900539\n",
      "\n",
      "Best Random State : 143 and Train R2 Score : 0.895815804886553\n",
      "Best Random State : 143 and Test R2 Score : 0.02640994792537732\n",
      "\n",
      "Best Random State : 144 and Train R2 Score : 0.789677435502983\n",
      "Best Random State : 144 and Test R2 Score : 0.8101981625423296\n",
      "\n",
      "Best Random State : 145 and Train R2 Score : 0.8836695409131288\n",
      "Best Random State : 145 and Test R2 Score : 0.2860496878651686\n",
      "\n",
      "Best Random State : 146 and Train R2 Score : 0.8656230735310653\n",
      "Best Random State : 146 and Test R2 Score : 0.5969651540722394\n",
      "\n",
      "Best Random State : 147 and Train R2 Score : 0.9306574355572573\n",
      "Best Random State : 147 and Test R2 Score : -0.057298695318246606\n",
      "\n",
      "Best Random State : 148 and Train R2 Score : 0.8548958083547578\n",
      "Best Random State : 148 and Test R2 Score : 0.6384919829605876\n",
      "\n",
      "Best Random State : 149 and Train R2 Score : 0.9009188667743558\n",
      "Best Random State : 149 and Test R2 Score : -0.07207595819432022\n",
      "\n",
      "Best Random State : 150 and Train R2 Score : 0.9059761068615497\n",
      "Best Random State : 150 and Test R2 Score : 0.1844916055232917\n",
      "\n",
      "Best Random State : 151 and Train R2 Score : 0.8556692157019239\n",
      "Best Random State : 151 and Test R2 Score : 0.6118968459208627\n",
      "\n",
      "Best Random State : 152 and Train R2 Score : 0.856153461750434\n",
      "Best Random State : 152 and Test R2 Score : 0.49023030740589557\n",
      "\n",
      "Best Random State : 153 and Train R2 Score : 0.8714792176745435\n",
      "Best Random State : 153 and Test R2 Score : 0.10925297556603653\n",
      "\n",
      "Best Random State : 154 and Train R2 Score : 0.8739300380405348\n",
      "Best Random State : 154 and Test R2 Score : 0.5935512897623068\n",
      "\n",
      "Best Random State : 155 and Train R2 Score : 0.9098356168464482\n",
      "Best Random State : 155 and Test R2 Score : 0.21612054021062355\n",
      "\n",
      "Best Random State : 156 and Train R2 Score : 0.9056427160507095\n",
      "Best Random State : 156 and Test R2 Score : 0.018814135402419163\n",
      "\n",
      "Best Random State : 157 and Train R2 Score : 0.9284659458955782\n",
      "Best Random State : 157 and Test R2 Score : -1.415904523483658\n",
      "\n",
      "Best Random State : 158 and Train R2 Score : 0.9320936659202462\n",
      "Best Random State : 158 and Test R2 Score : -0.6286282548444795\n",
      "\n",
      "Best Random State : 159 and Train R2 Score : 0.8597387912474085\n",
      "Best Random State : 159 and Test R2 Score : 0.4702777150003885\n",
      "\n",
      "Best Random State : 160 and Train R2 Score : 0.8379118213367833\n",
      "Best Random State : 160 and Test R2 Score : 0.29573331106639167\n",
      "\n",
      "Best Random State : 161 and Train R2 Score : 0.9461963972912196\n",
      "Best Random State : 161 and Test R2 Score : -2.212220552912394\n",
      "\n",
      "Best Random State : 162 and Train R2 Score : 0.8605014977297326\n",
      "Best Random State : 162 and Test R2 Score : 0.6550063169709973\n",
      "\n",
      "Best Random State : 163 and Train R2 Score : 0.8277509424953171\n",
      "Best Random State : 163 and Test R2 Score : 0.8116095548653739\n",
      "\n",
      "Best Random State : 164 and Train R2 Score : 0.8852281730510276\n",
      "Best Random State : 164 and Test R2 Score : -0.19069609205770366\n",
      "\n",
      "Best Random State : 165 and Train R2 Score : 0.8029437534235331\n",
      "Best Random State : 165 and Test R2 Score : 0.8964957824336895\n",
      "\n",
      "Best Random State : 166 and Train R2 Score : 0.8631181929950186\n",
      "Best Random State : 166 and Test R2 Score : 0.26974248369801146\n",
      "\n",
      "Best Random State : 167 and Train R2 Score : 0.8623154933688207\n",
      "Best Random State : 167 and Test R2 Score : 0.4297034939910789\n",
      "\n",
      "Best Random State : 168 and Train R2 Score : 0.8882521835310077\n",
      "Best Random State : 168 and Test R2 Score : 0.3975162996029591\n",
      "\n",
      "Best Random State : 169 and Train R2 Score : 0.8792831554467418\n",
      "Best Random State : 169 and Test R2 Score : -0.5300631055782947\n",
      "\n",
      "Best Random State : 170 and Train R2 Score : 0.9040021546266598\n",
      "Best Random State : 170 and Test R2 Score : -1.0212861833098872\n",
      "\n",
      "Best Random State : 171 and Train R2 Score : 0.8535452863051447\n",
      "Best Random State : 171 and Test R2 Score : 0.4759989415317861\n",
      "\n",
      "Best Random State : 172 and Train R2 Score : 0.9048920196419665\n",
      "Best Random State : 172 and Test R2 Score : 0.008969209409593448\n",
      "\n",
      "Best Random State : 173 and Train R2 Score : 0.8612074249724884\n",
      "Best Random State : 173 and Test R2 Score : 0.6018894003555644\n",
      "\n",
      "Best Random State : 174 and Train R2 Score : 0.9108761704183702\n",
      "Best Random State : 174 and Test R2 Score : 0.07671087271828125\n",
      "\n",
      "Best Random State : 175 and Train R2 Score : 0.8924255594065218\n",
      "Best Random State : 175 and Test R2 Score : 0.328360490101021\n",
      "\n",
      "Best Random State : 176 and Train R2 Score : 0.8346132660627523\n",
      "Best Random State : 176 and Test R2 Score : 0.7877847892466654\n",
      "\n",
      "Best Random State : 177 and Train R2 Score : 0.9314177167375006\n",
      "Best Random State : 177 and Test R2 Score : -2.1404813047935347\n",
      "\n",
      "Best Random State : 178 and Train R2 Score : 0.8337290608760369\n",
      "Best Random State : 178 and Test R2 Score : 0.7068531602835996\n",
      "\n",
      "Best Random State : 179 and Train R2 Score : 0.8881318259511451\n",
      "Best Random State : 179 and Test R2 Score : 0.3838758933815679\n",
      "\n",
      "Best Random State : 180 and Train R2 Score : 0.8230348828099943\n",
      "Best Random State : 180 and Test R2 Score : 0.7401268788090287\n",
      "\n",
      "Best Random State : 181 and Train R2 Score : 0.8483930418328021\n",
      "Best Random State : 181 and Test R2 Score : 0.71601910684937\n",
      "\n",
      "Best Random State : 182 and Train R2 Score : 0.9199489642644295\n",
      "Best Random State : 182 and Test R2 Score : -0.2086390757212231\n",
      "\n",
      "Best Random State : 183 and Train R2 Score : 0.876677918911895\n",
      "Best Random State : 183 and Test R2 Score : 0.2703865040483908\n",
      "\n",
      "Best Random State : 184 and Train R2 Score : 0.8677163435568543\n",
      "Best Random State : 184 and Test R2 Score : 0.610861700377491\n",
      "\n",
      "Best Random State : 185 and Train R2 Score : 0.9092844310992816\n",
      "Best Random State : 185 and Test R2 Score : -1.593678776358559\n",
      "\n",
      "Best Random State : 186 and Train R2 Score : 0.8702962274450361\n",
      "Best Random State : 186 and Test R2 Score : 0.45434894141873583\n",
      "\n",
      "Best Random State : 187 and Train R2 Score : 0.901814962200749\n",
      "Best Random State : 187 and Test R2 Score : -1.0210842220749226\n",
      "\n",
      "Best Random State : 188 and Train R2 Score : 0.8627299486357032\n",
      "Best Random State : 188 and Test R2 Score : 0.44447460308931197\n",
      "\n",
      "Best Random State : 189 and Train R2 Score : 0.7981931210826644\n",
      "Best Random State : 189 and Test R2 Score : 0.7216689344243834\n",
      "\n",
      "Best Random State : 190 and Train R2 Score : 0.8343779676109697\n",
      "Best Random State : 190 and Test R2 Score : 0.6813561446244574\n",
      "\n",
      "Best Random State : 191 and Train R2 Score : 0.836710734935959\n",
      "Best Random State : 191 and Test R2 Score : 0.7404072826800981\n",
      "\n",
      "Best Random State : 192 and Train R2 Score : 0.8298413024759907\n",
      "Best Random State : 192 and Test R2 Score : 0.692375905401442\n",
      "\n",
      "Best Random State : 193 and Train R2 Score : 0.8803180747237261\n",
      "Best Random State : 193 and Test R2 Score : -2.2814416162139164\n",
      "\n",
      "Best Random State : 194 and Train R2 Score : 0.8536115995364059\n",
      "Best Random State : 194 and Test R2 Score : 0.5310690179896346\n",
      "\n",
      "Best Random State : 195 and Train R2 Score : 0.8904026151388393\n",
      "Best Random State : 195 and Test R2 Score : 0.6290001934903783\n",
      "\n",
      "Best Random State : 196 and Train R2 Score : 0.8539819471395775\n",
      "Best Random State : 196 and Test R2 Score : 0.5499886693824163\n",
      "\n",
      "Best Random State : 197 and Train R2 Score : 0.8713706784670159\n",
      "Best Random State : 197 and Test R2 Score : 0.1907429079745232\n",
      "\n",
      "Best Random State : 198 and Train R2 Score : 0.867270492837714\n",
      "Best Random State : 198 and Test R2 Score : 0.5116723168793487\n",
      "\n",
      "Best Random State : 199 and Train R2 Score : 0.8913910867625321\n",
      "Best Random State : 199 and Test R2 Score : 0.2742189254212605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxScore = 0\n",
    "macRS = 0\n",
    "for i in range(1,200):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.23,random_state=i)\n",
    "    lr=LinearRegression()\n",
    "    lr.fit(x_train,y_train)\n",
    "    pred_train = lr.predict(x_train)\n",
    "    pred_test = lr.predict(x_test)\n",
    "    print(f'Best Random State : {i} and Train R2 Score : {r2_score(y_train,pred_train)}')\n",
    "    print(f'Best Random State : {i} and Test R2 Score : {r2_score(y_test,pred_test)}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Best Random State : 23 and Train R2 Score : 0.8273528079101595<br>\n",
    "        <br>\n",
    "Best Random State : 23 and Test R2 Score : 0.7812319076407748</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.23,random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance of model\n",
    "def performance(actual,pred):\n",
    "    print('Error ==> ')\n",
    "    print('Mean Absolute error : ',mean_absolute_error(actual,pred))\n",
    "    print('Mean Squared error : ',mean_squared_error(actual,pred))\n",
    "    print('R2_Score : ',r2_score(actual,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ==> \n",
      "Mean Absolute error :  4.388362740359034\n",
      "Mean Squared error :  30.797189818243584\n",
      "R2_Score :  0.7812319076407748\n"
     ]
    }
   ],
   "source": [
    "performance(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.944004960197801"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = cross_val_score(LinearRegression(),x,y,cv=10)\n",
    "cross.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso,Ridge,ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7812746478132153\n"
     ]
    }
   ],
   "source": [
    "# We can corrected by alpha value\n",
    "le = Lasso(alpha=0.0001)\n",
    "le.fit(x_train,y_train)\n",
    "predict = le.predict(x_test)\n",
    "le.score(x_train,y_train)\n",
    "\n",
    "print(r2_score(y_test,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The score is 78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.943691740647567"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val = cross_val_score(le,x,y,cv=10)\n",
    "cross_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8273528077486438"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Model\n",
    "re = Ridge(alpha=0.0001)\n",
    "re.fit(x_train,y_train)\n",
    "re.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Ridge is giving 82%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.943965765736464"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val = cross_val_score(re,x,y,cv=10)\n",
    "cross_val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7179715625258282\n",
      "Erro ==>\n",
      "Mean Absolute error :  4.987851266476606\n",
      "Mean Squared error :  34.70558461989886\n",
      "Cross Validation :  -7.021812327196119\n",
      "\n",
      "0.3586794381170487\n",
      "Erro ==>\n",
      "Mean Absolute error :  9.496217537067833\n",
      "Mean Squared error :  134.59662762091347\n",
      "Cross Validation :  -5.847696092613174\n",
      "\n",
      "0.17746992568223285\n",
      "Erro ==>\n",
      "Mean Absolute error :  9.199110897190863\n",
      "Mean Squared error :  130.74143458890723\n",
      "Cross Validation :  -6.54114430244923\n",
      "\n",
      "0.27731531654048813\n",
      "Erro ==>\n",
      "Mean Absolute error :  7.788038340251693\n",
      "Mean Squared error :  102.80343305349395\n",
      "Cross Validation :  -4.160333456071724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "kernel = ['linear','poly','rbf','sigmoid']\n",
    "\n",
    "for i in kernel:\n",
    "    sr = SVR(kernel=i)\n",
    "    sr.fit(x_train,y_train)\n",
    "    print(sr.score(x_train,y_train))\n",
    "    prec = sr.predict(x_test)\n",
    "    print('Erro ==>')\n",
    "    print('Mean Absolute error : ',mean_absolute_error(y_test,prec))\n",
    "    print('Mean Squared error : ',mean_squared_error(y_test,prec))\n",
    "    cross_val = cross_val_score(sr,x,y,cv=10)\n",
    "    print('Cross Validation : ',cross_val.mean())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - This is giving 71% and less error for linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso Regression param\n",
    "\n",
    "param = {'alpha' :[0.1,0.01,0.001,0.0001],\n",
    "         'selection' :['cyclic','random']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'selection': 'random'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_hp = GridSearchCV(Lasso(),param,cv=5)\n",
    "lasso_hp.fit(x_train,y_train)\n",
    "lasso_hp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8041130755251142\n"
     ]
    }
   ],
   "source": [
    "# By using alpha value\n",
    "\n",
    "le = Lasso(alpha=0.1,selection='random')\n",
    "le.fit(x_train,y_train)\n",
    "predict = le.predict(x_test)\n",
    "le.score(x_train,y_train)\n",
    "\n",
    "print(r2_score(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression Param\n",
    "\n",
    "param_r = {'alpha' :[0.1,0.01,0.001,0.0001],\n",
    "           'solver' :['auto','svd','cholesky','lsqr','sparse_cg','sag','saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'solver': 'saga'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_hp = GridSearchCV(Ridge(),param_r,cv=5)\n",
    "ridge_hp.fit(x_train,y_train)\n",
    "ridge_hp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8041590369937879\n"
     ]
    }
   ],
   "source": [
    "# Ridge Model\n",
    "\n",
    "re = Ridge(alpha=0.1,solver='saga')\n",
    "re.fit(x_train,y_train)\n",
    "predict = le.predict(x_test)\n",
    "re.score(x_train,y_train)\n",
    "\n",
    "print(r2_score(y_test,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Both Lasso & Ridge giving 80.4% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Base_ball_case_study.obj']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(le,'Base_ball_case_study.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Base_ball_case_study1.obj']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(re,'Base_ball_case_study1.obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1 = joblib.load('Base_ball_case_study.obj')\n",
    "mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.1, solver='saga')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1 = joblib.load('Base_ball_case_study1.obj')\n",
    "mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
